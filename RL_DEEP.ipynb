{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f5da77-9ace-4f41-9eae-a369dc1aeee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "!pip install gym\n",
    "!pip install copy\n",
    "!pip install pylab\n",
    "!pip install random\n",
    "!pip install os\n",
    "!pip install gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9751620-1a25-483c-b45f-bb7642264b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import json\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "import random\n",
    "import pylab\n",
    "import os\n",
    "import gzip\n",
    "from urllib.request import urlopen\n",
    "from collections import deque\n",
    "from keras import layers, models\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4f794e-02a9-4798-a0d1-8cdf46d6cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFiles/AMAZON_FASHION.json.gz\n",
    "# Load JSON data\n",
    "data = []\n",
    "with gzip.open('AMAZON_FASHION.json.gz') as f:\n",
    "    for l in f:\n",
    "        data.append(json.loads(l.strip()))\n",
    "# Let's take a peek at the first row and the total number of rows\n",
    "print(len(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1706af-bf4d-46e1-b0ee-a1d2f750b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for easier data manipulation\n",
    "df = pd.DataFrame(data)\n",
    "df = df[['overall','verified','reviewerID','asin','style','reviewerName','reviewText', 'summary','reviewTime']]\n",
    "# Filter verified reviews with non-null overall ratings\n",
    "filtered_df = df[(df['verified'] == True) & (~df['overall'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648572b3-a44e-4a4d-8d54-15e21cdfaf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create FashionProduct class for a product representation from reviews\n",
    "class FashionProduct() : pass\n",
    "class Reviewer() : pass\n",
    "# Group reviews by reviewers and select users with more than ten purchases\n",
    "reviewers = {}\n",
    "grouped_df_reviwerId = filtered_df.groupby('reviewerID')\n",
    "for reviewerId, group in grouped_df_reviwerId:\n",
    "    products = group[group['asin'].notna()]['asin'].unique()\n",
    "    if len(products) > 10:\n",
    "        reviewer = Reviewer()\n",
    "        reviewer.reviewerId = reviewerId\n",
    "        reviewer.products = products\n",
    "        reviewers[reviewerId] = reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf9ae8-fc01-4c27-bcf1-b98d410a69e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataset to include only reviewers with more than ten products\n",
    "filtered_df = filtered_df[(filtered_df['reviewerID'].isin([reviewer.reviewerId for reviewer in reviewer_values]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b68916-88d7-4ca7-b23e-813700ef7b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group reviews by product ASIN, reviewerID, and reviewTime\n",
    "filtered_df['reviewTime'] = pd.to_datetime(filtered_df['reviewTime'])\n",
    "filtered_df.sort_values('reviewTime')\n",
    "grouped_df = filtered_df.groupby(['asin', 'reviewerID', 'reviewTime'], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc623147-d910-405e-8526-bf1941b32ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spacy for nlp related noun extraction, stopword removal and others\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# extract nouns from review text\n",
    "def extract_nouns(doc):\n",
    "    return \" \".join([token.text for token in doc if token.pos_ == \"NOUN\" or token.pos_ == \"PROPN\"])\n",
    "\n",
    "# Initialize a dictionary to store product features as states\n",
    "states = {}\n",
    "products = {}\n",
    "\n",
    "# Iterate over each product\n",
    "for (product_asin, reviewerId, reviewTime), group in grouped_df:\n",
    "    if (product_asin, reviewerId) in states: continue\n",
    "    product = FashionProduct()\n",
    "    product.product_asin = product_asin\n",
    "    product.reviewerId = reviewerId\n",
    "    product.time = reviewTime\n",
    "    if product_asin not in products:\n",
    "        products[product_asin] = product\n",
    "        p= products[product_asin]\n",
    "        p.reviewers = set()\n",
    "        p.sizes = set()\n",
    "        p.colors = set()\n",
    "        p.reviews = set()\n",
    "        p.rating =[]\n",
    "\n",
    "    product.reviewers = products[product_asin].reviewers\n",
    "\n",
    "\n",
    "\n",
    "    # extract size and color metadata from style column\n",
    "    styles=  group[group['style'].notna()]['style']\n",
    "    sizes = styles.apply(lambda x: x.get(\"Size:\", \"\") if \"Size:\" in x else x.get(\"Size Name:\", \"\")).unique().tolist()\n",
    "    colors = styles.apply(lambda x: x.get(\"Color:\", \"\")).unique().tolist()\n",
    "\n",
    "    products[product_asin].sizes.update(sizes)\n",
    "    products[product_asin].colors.update(colors)\n",
    "\n",
    "    #extract other noun metadata from review text\n",
    "    reviews = group[group['reviewText'].notna()]['reviewText']\n",
    "    reviews = \" \".join(reviews.apply(lambda x: \" \".join([extract_nouns(chunk) for chunk in nlp(x).noun_chunks]).strip()).unique())\n",
    "    products[product_asin].reviews.update(reviews)\n",
    "    #using rms instead of average for review ratings to give slightly higher weightage to good reviews\n",
    "    ratings = group[group['overall']>0]['overall'].tolist()\n",
    "    products[product_asin].rating.extend(ratings)\n",
    "    product.ratings = np.sqrt(np.mean( [r**2 for r in products[product_asin].rating]))\n",
    "\n",
    "    sizes = \" \".join(products[product_asin].sizes)\n",
    "    colors = \" \".join(products[product_asin].colors)\n",
    "    reviews = \" \".join(products[product_asin].reviews)\n",
    "    product.metadata= \" \".join((reviews+\" \"+sizes+\" \"+colors).split())\n",
    "\n",
    "    # add past product and reviewer's product metadata\n",
    "    # we will take metatdata of last 2 reviewer only as large metadata causes memory issues\n",
    "    for reviewer in list(product.reviewers)[-2:]:\n",
    "        state = states[(product_asin, reviewer)]\n",
    "        product.metadata += \" \"+state.metadata\n",
    "\n",
    "    # keep past reviewer list\n",
    "    products[product_asin].reviewers.add(reviewerId)\n",
    "\n",
    "    states[(product_asin, reviewerId)] = product\n",
    "\n",
    "states_list= list(states.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3faa9-3175-4325-b594-bb93a6327881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add past product and reviewer's product metadata to the current state\n",
    "# Code already implemented in previous section, shown here for clarity only\n",
    "for reviewer in list(product.reviewers)[-2:]:\n",
    "    state = states[(product_asin, reviewer)]\n",
    "    product.metadata += \" \" + state.metadata\n",
    "\n",
    "\n",
    "# Create states for users and enhance metadata with past products\n",
    "for state in states_list:\n",
    "    if state.reviewerId not in users:\n",
    "        users[state.reviewerId] = Reviewer()\n",
    "        users[state.reviewerId].products = set()\n",
    "    for prod1 in list(users[state.reviewerId].products)[-2:]:\n",
    "        state1 = states[(prod1, state.reviewerId)]\n",
    "        state.metadata += state1.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccd1f04-59e7-4d36-898f-275a21bace32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove states with empty metadata\n",
    "states_list = [s for s in states_list if s.metadata.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c132c6-6cf9-4cf2-b08f-c93c45d05eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc567cbb-48e4-40ce-91e1-25d844ce2193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd84ae4f-714f-49ac-bf4b-8316c441f931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c7163a-6e41-4baf-a23e-f39ca00a57bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf14fa-e7d0-443b-89ec-a0c91249100e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e48a2ef-d84d-4c62-af0c-d48ca1b74896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee59bd1-85eb-4e52-8a39-a7c5ce7f6332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5c413d-4c2a-4744-be30-9220a037e348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c599a838-fbe9-41b3-87c6-b59109a6265b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
